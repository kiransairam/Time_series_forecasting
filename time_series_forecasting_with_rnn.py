# -*- coding: utf-8 -*-
"""Time series forecasting with RNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qxXswkQ7aiuMRSZRWFPB4jm1muNMyBW4

#Deep Learning Assignment Time series forecasting with RNNs

Required packages to install
"""

!pip install pandas
import os
import datetime
import matplotlib as mpl
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import regularizers
from tensorflow.keras.optimizers import Adam

"""##Inspecting and Cleaning data (3pt)"""

!wget --no-check-certificate "https://uofi.box.com/shared/static/4bjhkchbo2chssjovpl97jduvcpy29v8" -O csse_covid_19_daily_reports_us.csv

#Getting the Data
# downloading the files from dropbox
#!wget --no-check-certificate  "https://uofi.box.com/shared/static/xvogtt25vuv0u5tzhvqttysr7ux5263i.zip" -O cats-vs-dogs.zip

data_set = pd.read_csv("csse_covid_19_daily_reports_us.csv")

"""Convert the "Last_Update" column to datetime and use sort_values to sort the dataframe first by "Province_State" and then by "Last_Update"
"""

data_set['Last_Update'] = pd.to_datetime(data_set['Last_Update'])
data_set_sort_values(['Province_State', 'Last_Update'], inplace=True)

"""Remove the rows where the Province_State is "Recovered", "American Samoa" "Diamond Princess", "Grand Princess", "Virgin Islands", and "Northern Mariana Islands"
"""

states_delete = ["Recovered", "American Samoa", "Diamond Princess", "Grand Princess", "Virgin Islands", "Northern Mariana Islands"]
data_set = data_set[~data_set["Province_State"].isin(states_delete)]
data_set

"""Count and print the number of rows for each remaining Province_State"""

state_counts = data_set.groupby("Province_State").size()
print(state_counts)

"""Drop all columns except the following: "Last_Update", "Incident_Rate", "Confirmed", "Deaths", "Province_State"
"""

columns_keep = ["Last_Update", "Incident_Rate", "Confirmed", "Deaths", "Province_State"]
data_set = data_set[columns_keep]
data_set

"""Check if there are any missing values in the remaining columns. If so, replace them using commonsense or use the fillna() function to fill the missing values with zero."""

print(data_set.isnull().sum())
data_set.fillna(0, inplace=True)

"""Replace the "Last_Update" column with four other columns: "year", "month","day of the week", and "day of the month" Convert "Last_Update" column to datetime format df["Last_Update"] = pd.to_datetime(df["Last_Update"])"""

df["year"] = df["Last_Update"].dt.year
df["month"] = df["Last_Update"].dt.month
df["day_of_week"] = df["Last_Update"].dt.dayofweek
df["day_of_month"] = df["Last_Update"].dt.day
df = df.drop("Last_Update", axis=1)

"""##Prepare time series for each Province_state (6pt)"""

import pandas as pd
import numpy as np
import tensorflow as tf

def convert_aggregated_to_MA(ds, window=7):
    ds = ds.diff()

    for i in range(0, len(ds)):
        if ((ds.iloc[i]<0)):
            if (ds.iloc[i-1]>0):
                ds.iloc[i]*ds.iloc[i-1]
            else:
                ds.iloc[i] = 0
    return ds.rolling(window).mean()

uniq_states = df.Province_State.unique()
print(uniq_states)

datasets = []

for state in uniq_states:
    state_df = df.loc[df['Province_State'] == state]

    ConfirmedMA = convert_aggregated_to_MA(state_df.Confirmed)
    DeathsMA =  convert_aggregated_to_MA(state_df.Deaths)

    state_df['Confirmed'] =  ConfirmedMA
    state_df['Deaths'] = DeathsMA

    state_df = state_df.drop(['Province_State'], axis = 1)
    state_df = state_df.dropna()

    #get the number of samples
    n = len(state_df)

    # use,  the first 60% of samples for training
    num_train_samples = int(n*0.6)

    #use the next 15% of samples for validation
    num_val_samples=int(n*0.15)

    #use the last 25% of samples for testing
    num_test_samples = int(n*0.25)

    train_mean = state_df[:num_train_samples].mean(axis=0)
    train_std = state_df[:num_train_samples].std(axis=0)
    state_df = (state_df - train_mean) / train_std

    #sequence_length is the number of past observations you want to use for prediction.
    sequence_length = 60
    batch_size = 256

    # delay is the forecasting interval, that is, how many time steps into the future you want to predict.
    delay=sequence_length+30-1

    train_ds = keras.preprocessing.timeseries_dataset_from_array(
        data=state_df[:-delay].to_numpy(),
        targets=state_df['Deaths'][delay:],
        sequence_length=sequence_length,
        batch_size=batch_size,
        start_index=0,
        end_index=num_train_samples)

    val_ds = keras.preprocessing.timeseries_dataset_from_array(
        data=state_df[:-delay].to_numpy(),
        targets=state_df['Deaths'][delay:],
        sequence_length=sequence_length,
        batch_size=batch_size,
        start_index=num_train_samples,
        end_index=num_train_samples + num_val_samples)

    test_ds = keras.preprocessing.timeseries_dataset_from_array(
        data=state_df[:-delay].to_numpy(),
        targets=state_df['Deaths'][delay:],
        sequence_length=sequence_length,
        batch_size=batch_size,
        start_index=num_train_samples + num_val_samples)

    datasets.append({'train': train_ds, 'val': val_ds, 'test': test_ds})

train_dataset = datasets[0]['train']
val_dataset = datasets[0]['val']
test_dataset = datasets[0]['test']

for ds in datasets[1:]:
    train_dataset = train_dataset.concatenate(ds['train'])
    val_dataset = val_dataset.concatenate(ds['val'])
    test_dataset = test_dataset.concatenate(ds['test'])

train_mean
train_std

for samples, targets in train_dataset.take(1):
    print(f"samples.shape:{samples.shape}  targets.shape:{targets.shape}")
    #print(f"x={samples[0]},y={targets[0]}")

for samples, targets in val_dataset.take(1):
    print(f"samples.shape:{samples.shape}  targets.shape:{targets.shape}")
    #print(f"x={samples[0]},y={targets[0]}")

for samples, targets in test_dataset.take(1):
    print(f"samples.shape:{samples.shape}  targets.shape:{targets.shape}")
    #print(f"x={samples[0]},y={targets[0]}")

print("number of test samples", len(train_dataset))
print("number of test samples", len(val_dataset))
print("number of test samples", len(test_dataset))



"""##A Commonsense Baseline Model (3 pt)"""

def evaluate_model(dataset, model=None):
  total_abs_err = 0
  num_sequences = 0
  # the index of the target variable in the data.


  temp_index=2
  for samples, targets in dataset:

    #if model is None, use commonsense baseline, that is predict the target to be its last measurement in the input sequence
    if model==None:
      preds = samples[:, -1, temp_index]

    #if model is not None, get its predictions
    else:
      preds= model.predict(samples).flatten()
    #preds, targets=unnormalize(preds, targets, train_mean[temp_index], train_std[temp_index])

    # add the absolute difference between the predictions and taragets to total_abs_err
    #print(f" {preds}  {targets}  {np.sum(np.abs(preds - targets))}")
    total_abs_err += np.sum(np.abs(preds - targets))

    # add the number of sequences in this batch to num_sequences
    num_sequences += samples.shape[0]

  #get the average absolute error
  return total_abs_err / num_sequences

#print(f"Train MAE Baseline: {evaluate_model(global_train):.2f}")
print(f"Validation MAE Baseline: {evaluate_model(val_dataset):.2f}")
print(f"Test MAE Baseline: {evaluate_model(test_dataset):.2f}")

"""##A small Fully Connected Model (7pt)"""

inputs = keras.Input(shape=(sequence_length , num_features))
x = layers.Flatten()(inputs)
x = layers.Dense(32, activation="relu")(x)
outputs = layers.Dense(1)(x)
fully_connected_model = keras.Model(inputs, outputs)

initial_lr = 1e-3
lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(
   boundaries=[10, 20, 30, 40],
   values=[initial_lr, initial_lr * 0.1, initial_lr * 0.01, initial_lr * 0.001, initial_lr * 0.0001],
)

opt = tf.keras.optimizers.RMSprop(learning_rate=lr_schedule)

fully_connected_model.compile(optimizer=opt, loss="mse", metrics=["mae"])

# Checkpoint the best model
checkpoint = keras.callbacks.ModelCheckpoint("fully_connected.keras", save_best_only=True)

# Stop training if validation loss does not improve for 5 consecutive epochs
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, min_delta=1e-3, restore_best_weights=True)

history = fully_connected_model.fit(train_dataset,
    epochs=50,
    validation_data=val_dataset,
    callbacks=[checkpoint, early_stopping]
)

loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.figure()
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()
plt.show()

print(f"Validation MAE fully connected: {evaluate_model(val_dataset , model=fully_connected_model):.2f}")
#print(f"Test MAE fully connected: {evaluate_model(global_test , model=fully_connected_model):.2f}")

"""It looks like the model is performing well, with the loss and MAE decreasing significantly over the first few epochs. However, it's important to keep monitoring the validation loss and MAE to make sure the model isn't overfitting. From the current results, it seems that the model might be overfitting a bit, as the training loss and MAE are significantly lower than the validation loss and MAE.

##L2 regularization
"""

inputs = keras.Input(shape=(sequence_length , num_features))
x = layers.Flatten()(inputs)
x = layers.Dense(16, activation='relu')(x)
x=  layers.Dropout(0.2)(x)
x = layers.Dense(16, activation='relu', kernel_initializer=tf.keras.initializers.he_normal(seed=1), kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)
x=  layers.Dropout(0.2)(x)
outputs = layers.Dense(1)(x)
regularized_fully_connected_model = keras.Model(inputs, outputs)

def lr_schedule(epoch):
    lr = 1e-3 if epoch > 10: lr *= 0.1 elif epoch > 5: lr *= 0.5
    return lr

opt = tf.keras.optimizers.RMSprop(learning_rate=1e-3)

regularized_fully_connected_model.compile(optimizer=opt, loss="mse", metrics=["mae"])

# check point the best model
checkpoint= keras.callbacks.ModelCheckpoint("regularized_fully_connected_model.keras",save_best_only=True)

#stop trianing if validation loss does not imrove for 5 consecutive epochs
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, min_delta=1e-3, restore_best_weights=True)

history = regularized_fully_connected_model.fit(train_dataset,
epochs=50,
validation_data=val_dataset,
callbacks=[checkpoint, early_stopping])

print(f"Validation MAE regularization connected: {evaluate_model(val_dataset , model=regularized_fully_connected_model):.2f}")
#print(f"Test MAE regularization connected: {evaluate_model(global_test , model=regularized_fully_connected_model):.2f}")

"""##Yes,regularization help slightly with overfitting

##Tune the hyper-parameters of the model
"""

!pip install -q -U keras-tuner

def model_builder(hp):

  #creating a placeholder for each hyperparameter with a range of values for each hyperparameter we want to tune
  hp_units = hp.Int('units', min_value = 16, max_value = 512, step = 32)
  hp_num_layers = hp.Int('num_layers', min_value = 1, max_value = 10, step=1)
  hp_dropout_rate = hp.Float('dropout', min_value = 0,max_value = 0.5, step = 0.1)
  hp_learningrate=hp.Float("initial_learning_rate",min_value=1e-4, max_value=1e-2, sampling='log')
  hp_lr_decay_steps=hp.Choice("lr_decay_steps", values=(1000, 5000, 10000))
  hp_weight_decay=hp.Float("weight_decay",min_value=1e-3, max_value=1e-1, sampling='log')


  inputs = keras.Input(shape=(sequence_length, num_features))
  x = layers.Flatten()(inputs)

  #hidden layers
  for _ in range(hp_num_layers):
    x=layers.Dense(hp_units, kernel_regularizer=tf.keras.regularizers.l2(hp_weight_decay))(x)
    x= layers.ReLU()(x)
    x=layers.Dropout(hp_dropout_rate)(x)

  outputs = layers.Dense(1)(x)
  model = keras.Model(inputs, outputs)

  lr_schedule = keras.optimizers.schedules.CosineDecay(
  initial_learning_rate=hp_learningrate,
  decay_steps=hp_lr_decay_steps, alpha=1e-2)

  opt = tf.keras.optimizers.RMSprop(learning_rate=lr_schedule)

  model.compile(optimizer=opt, loss="mse", metrics=["mae"])

  return model

import keras_tuner as kt
from tensorflow import keras
from tensorflow.keras import layers
import tensorflow as tf
import kerastuner as kt
from keras import regularizers



tuner = kt.Hyperband(model_builder,
                     objective='val_loss',
                     max_epochs=20,
                     factor=3,
                     directory='hyperparameter_runs',
                     project_name='fullyconnected')

early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, min_delta=1e-4, restore_best_weights=True)

tensorboard = keras.callbacks.TensorBoard(
log_dir="/content/drive/MyDrive/Assignment_4/hyperband",
histogram_freq=1
)

#remove the log directory if already exists
!rm -rf "/content/drive/MyDrive/Assignment_4/hyperband"
tuner.search(train_dataset,
            validation_data = val_dataset,
            epochs = 50,
            callbacks=[early_stopping, tensorboard ],
            verbose = 1)

best_hps=tuner.get_best_hyperparameters()[0]
best_model_fully_connected = tuner.get_best_models(num_models=1)[0]
print(f"""
The hyperparameter search is complete.
The optimal number of units  is {best_hps.get('units')}.
The optimal number of layers  is {best_hps.get('num_layers')}.
The optimal learning rate for the optimizer is {best_hps.get('initial_learning_rate')}.
The optimal dropout is {best_hps.get('dropout')}.
The optimal decay_steps for cosine schedule is {best_hps.get('lr_decay_steps')}.
The optimal weight decay is {best_hps.get('weight_decay')}.
""")

test_loss, test_acc = best_model_fully_connected.evaluate(test_dataset)
print('\n test acc:', test_acc)


val_loss, val_acc = best_model_fully_connected.evaluate(val_dataset)
print('\n val acc:', test_acc)

print(f"Validation MAE Tuned Fully connected model: {evaluate_model(val_dataset, best_model_fully_connected):.2f}")
print(f"Test MAE Tuned Fully connected model: {evaluate_model(test_dataset, best_model_fully_connected):.2f}")

"""##the tuned fully connected model does better than the baseline model on the validation data, as the MAE of the tuned model on the validation data is 0.77 which is less than the baseline model's validation MAE of 0.96.

#A Recurrent Model (7 pts)
"""

#every sample in train/validation/test is a 2d tensor of shape (sequence_length, num_features)

def build_lstm(sequence_length, num_features):
  inputs = keras.Input(shape=(sequence_length, num_features))
  x = layers.LSTM(16)(inputs)
  outputs = layers.Dense(1)(x)
  lstm_model = keras.Model(inputs, outputs)
  return lstm_model

  def lr_schedule(epoch):
    lr = 1e-3 if epoch > 10: lr *= 0.1 elif epoch > 5: lr *= 0.5
    return lr

opt = tf.keras.optimizers.RMSprop(learning_rate=1e-3)


lstm_model= build_lstm(sequence_length, num_features)

# check point the model with lowest validation loss
checkpoint= keras.callbacks.ModelCheckpoint("temp_lstm.keras",save_best_only=True)

#stop trianing if validation loss does not imrove for 5 consecutive epochs
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, min_delta=1e-4, restore_best_weights=True)


lstm_model.compile(optimizer="rmsprop", loss="mse", metrics=["mae"])
history = lstm_model.fit(train_dataset,
epochs=50,
validation_data=val_dataset,
callbacks=[checkpoint, early_stopping])

loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.figure()
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss recurrent baseline')
plt.legend()
plt.show()

print(f"Validation MAE lstm: {evaluate_model(val_dataset, model=lstm_model):.2f}")



"""## it showing the slightly overfitting.

##Stacking recurrent layers
"""

def build_stacked_lstm(sequence_length, num_features):
  inputs = keras.Input(shape=(sequence_length, num_features))
  x = layers.GRU(32, recurrent_dropout=0.5,return_sequences=True)(inputs)
  x = layers.GRU(32, recurrent_dropout=0.5)(x)
  x = layers.Dropout(0.5)(x)
  outputs = layers.Dense(1)(x)
  model = keras.Model(inputs, outputs)
  return model

  def lr_schedule(epoch):
    lr = 1e-3 if epoch > 10: lr *= 0.1 elif epoch > 5: lr *= 0.5
    return lr

opt = tf.keras.optimizers.RMSprop(learning_rate=1e-3)

stacked_lstm_model= build_stacked_lstm(sequence_length, num_features)
# check point the best model
checkpoint= keras.callbacks.ModelCheckpoint("temp_stacked_lstm.keras",save_best_only=True)

stacked_lstm_model.compile(optimizer="rmsprop", loss="mse", metrics=["mae"])
history = stacked_lstm_model.fit(train_dataset,
epochs=50,
validation_data=val_dataset,
callbacks=[checkpoint, early_stopping])

loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.figure()
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()
plt.show()

print(f"Validation MAE lstm: {evaluate_model(val_dataset, model=stacked_lstm_model):.2f}")

def model_builder(hp):

  #creating a placeholder for each hyperparameter with a range of values for each hyperparameter we want to tune
  hp_units = hp.Int('units', min_value = 16, max_value = 512, step = 32)
  hp_num_layers = hp.Int('num_layers', min_value = 1, max_value = 10, step=1)
  hp_dropout_rate = hp.Float('dropout', min_value = 0,max_value = 0.5, step = 0.1)
  hp_learningrate=hp.Float("initial_learning_rate",min_value=1e-4, max_value=1e-2, sampling='log')
  hp_lr_decay_steps=hp.Choice("lr_decay_steps", values=(1000, 5000, 10000))
  hp_weight_decay=hp.Float("weight_decay",min_value=1e-3, max_value=1e-1, sampling='log')


  inputs = keras.Input(shape=(sequence_length, num_features))
  x = layers.Flatten()(inputs)

  #hidden layers
  for _ in range(hp_num_layers):

    x = layers.GRU(32, recurrent_dropout=0.5,return_sequences=True)(inputs)
    x = layers.GRU(32, recurrent_dropout=0.5)(x)
    x = layers.Dropout(0.5)(x)


    #x=layers.Dense(hp_units, kernel_regularizer=tf.keras.regularizers.l2(hp_weight_decay))(x)
    #x= layers.ReLU()(x)
    #x=layers.Dropout(hp_dropout_rate)(x)

  outputs = layers.Dense(1)(x)
  model = keras.Model(inputs, outputs)

  lr_schedule = keras.optimizers.schedules.CosineDecay(
  initial_learning_rate=hp_learningrate,
  decay_steps=hp_lr_decay_steps, alpha=1e-2)

  opt = tf.keras.optimizers.RMSprop(learning_rate=lr_schedule)

  model.compile(optimizer=opt, loss="mse", metrics=["mae"])

  return model

import keras_tuner as kt
from tensorflow import keras
from tensorflow.keras import layers
import tensorflow as tf
import kerastuner as kt
from keras import regularizers



tuner = kt.Hyperband(model_builder,
                     objective='val_loss',
                     max_epochs=20,
                     factor=3,
                     directory='hyperparameter_runs',
                     project_name='stacked_layer')

early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, min_delta=1e-4, restore_best_weights=True)

tensorboard = keras.callbacks.TensorBoard(
log_dir="/content/drive/MyDrive/Assignment_4/stacked_layer",
histogram_freq=1
)

#remove the log directory if already exists
!rm -rf "/content/drive/MyDrive/Assignment_4/stacked_layer"
tuner.search(train_dataset,
            validation_data = val_dataset,
            epochs = 50,
            callbacks=[early_stopping, tensorboard ],
            verbose = 1)

best_hps=tuner.get_best_hyperparameters()[0]
best_model_connected = tuner.get_best_models(num_models=1)[0]
print(f"""
The hyperparameter search is complete.
The optimal number of units  is {best_hps.get('units')}.
The optimal number of layers  is {best_hps.get('num_layers')}.
The optimal learning rate for the optimizer is {best_hps.get('initial_learning_rate')}.
The optimal dropout is {best_hps.get('dropout')}.
The optimal decay_steps for cosine schedule is {best_hps.get('lr_decay_steps')}.
The optimal weight decay is {best_hps.get('weight_decay')}.
""")

print(f"Validation MAE lstm: {evaluate_model(val_dataset, model=best_model_connected):.2f}")



"""##the tuned LSTM model with a validation MAE of 0.74 performs better than the baseline model with a validation MAE of 0.96. This indicates that the hyperparameter tuning process has resulted in a better model performance on the validation data.

##A 1D Convolutional Model (4 pts)
"""

def build_1dconv(sequence_length, num_features):
  inputs = keras.Input(shape=(sequence_length, num_features))

  # a 1D convolutional layer with 8 filters and a kernel/window of size 24
  x = layers.Conv1D(8, 14, activation="relu")(inputs)
  x = layers.MaxPooling1D(2)(x)

  # a 1D convolutional layer with 8 filters and a kernel of size 12
  x = layers.Conv1D(8, 14, activation="relu")(x)
  x = layers.MaxPooling1D(2)(x)

  # a 1D convolutional layer with 8 filters and a kernel of size 6
  #x = layers.Conv1D(8, 6, activation="relu")(x)

  # a golobal average pooling layer that takes the global average along the temporal dimension
  x = layers.GlobalAveragePooling1D()(x)
  outputs = layers.Dense(1)(x)
  model = keras.Model(inputs, outputs)
  return model
conv1D_model= build_1dconv(sequence_length, num_features)

conv1D_model.summary()

# check point the best model
checkpoint= keras.callbacks.ModelCheckpoint("temp_conv1d.keras",save_best_only=True)

conv1D_model.compile(optimizer="rmsprop", loss="mse", metrics=["mae"])
history = conv1D_model.fit(train_dataset,
epochs=50,
validation_data=val_dataset,
callbacks=[checkpoint, early_stopping])

loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.figure()
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()
plt.show()

print(f"validation MAE for Conv1D model: {evaluate_model(val_dataset, model=conv1D_model):.2f}")

"""##Compute the MAE of the best model ( out of all the models you tried)"""

print(f"Validation MAE lstm: {evaluate_model(val_dataset, model=best_model_connected):.2f}")

"""## Validation MAE Baseline: 0.96
## Validation MAE Tuned Fully connected model: 0.77
## Validation MAE lstm (Stacked) : 0.74
## Validation MAE for Conv1D model: 0.88

##The LSTM model has a validation MAE of 0.74, which is the lowest validation MAE among all the models tried, indicating that it is the best model for this task.

##On the other hand, the Conv1D model has a validation MAE of 0.88, which is lower than the baseline model but higher than the other two models. This indicates that the Conv1D model is performing better than the baseline model, but not as good as the other two models.
"""